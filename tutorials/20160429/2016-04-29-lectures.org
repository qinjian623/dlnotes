#+LATEX_HEADER: \usepackage{xeCJK}
#+LaTeX_CLASS_OPTIONS: [a4paper, twocolumn]

* Checklist [1/2]                                                  :noexport:
  - [X] 历史
  - [ ]  目前进展

* 资料 
  1. [[http://www.deeplearningbook.org/][/Deep Learning/]] [[https://github.com/HFTrader/DeepLearningBook][PDF on github]]
  2. [[http://cs231n.github.io/][CS231n Convolutional Neural Networks for Visual Recognition]] 
  3. [[https://www.coursera.org/course/neuralnets][Neural Networks for Machine Learning]]
  4. [[http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial][UFLDL Tutorial]]

* 结构
** 历史与现况
*** 历史
    从1940s到2014: http://people.idsia.ch/~juergen/DeepLearning15May2014.pdf
*** 现况
    1. Andrew Ng, [[ftp://10.10.24.13/videos/dl/detection-demo-VEqhw9OgDl0.mp4][Highway]]
    2. NLP
    3. Imagenet
    4. ipython notebook
** 监督机器学习的结构
   假设我们获得了一部分的房价与房屋面积数据, 如下:
   #+attr_html: :width 500px
   [[./imgs/house_prices.png]]
   
   对应的一条数据的格式是 $\left \{  x, y \right \}$, 其中x为面积, y为房价. 这些数据的(一部分)集合 $\left \{  (x_i, y_i); i = 1, ..., m \right \}$ 可以叫做训练集(training set)

   那么, 监督机器学习可以如下理解: 
#+BEGIN_QUOTE
利用已知的训练集, 学习一个函数 h: $X\rightarrow Y$, h(x)的结果对y的预测达到我们预设的 _足够好_ 的标准.
#+END_QUOTE
   如果我们需要根据房屋面积预测房价, 那么我们需要学习一个函数 h(x), 输入x为面积, 输出y为房价. 最简单的一个可以学习的函数就是线性函数, 对于y的预测, 属于回归问题.
** 线性回归/感知机
*** 介绍与分类原理
**** 线性回归的形式
\begin{equation}
y = W*x + b
\end{equation}
其中, $W= {w_0, w_1, ... , w_n}$ , $ x = {x_0, x_1, ..., x_n}$, 
如果将向量形式展开, 变成标量的格式, 则表达式为: 
\begin{equation}
y = \sum_0^n{w_i * x_i} + b
\end{equation}
     模型的参数W需要通过学习来获得. 那么, 如何学习W的具体值?
     根据我们之前对于监督机器学习的理解, 我们需要一个预设的"足够好"的标准. 这一标准是需要人工选择的, 机器无法判断h(x)的结果与对应的y需要符合什么样的标准才是"好".
**** Cost Function
     对于上面的例子, 我们可以这样考虑: 
#+BEGIN_SRC quote
h(x)的预测与实际y值之间的差别越小越好. 
特别是, 如果在理想情况下, 应该是一模一样. 
#+END_SRC
于是我们可以定义: |h(x) - y|作为评价指标. 考虑到绝对值后续会遇到判断的问题, 更加简单的形式可以定义为 $J = \frac{1}{2}\left ( h(x) - y \right ) ^2$. 
那么针对这一问题的学习过程就是, 通过改变W的值来最小化 $J$ 的过程.
**** 学习过程
     为了获得 $J$ 的最小值, 我们可以有如下选择:
     1. 不断随机W值, 找到最小值.
     2. 在一个随机的W值的基础上, 使用随机的修正值.
     3. 在一个随机的w值的基础上, 使用有目的的修正值.
     
        
     很明显的, 第三种方法是效率上最高的. 那么, 如何获得 _有目的_ 的修正值? $J$ 在最小化的情况下, 其导数是为0的, 而恰好 $J$ 是一个理想的凸函数, 只需要沿着导数下降的方向进行修正, 就能保证到达 $J$ 的最小值.
     所以, 修正的方法就是:

\begin{equation*}
w_j = w_j - \alpha \frac{d}{dw_j} J(W)
\end{equation*}

其中 \alpha 被称为 *learning rate* . 这一方法就是在函数的梯度中, 找到最快速下降的方向. 


为了实现这样的更新算法, 我们需要知道 $\frac{d}{dw_j} J(W)$ 这一项. 我们已知 $J$ 的形式, 于是针对每个w_j 求偏导就可以:
\begin{align*}
\frac{d}{dw_j} J(W) &= \frac{d}{dw_j} \frac{1}{2} (h_w(x) - y)^2 \\
&= 2 \cdot  \frac{1}{2}(h_w(x) - y) \cdot \frac{d}{dw_j} (h_w(x) - y) \\
&= (h_w(x) - y) \cdot \frac{d}{dw_j} (\sum_{i=0}^{n}w_ix_i - y) \\
&= (h_w(x) - y) x_j
\end{align*}

于是我们每次更新的就方式就是:
\begin{equation*}
w_j = w_j - \alpha(h(x) - y)x_j
\end{equation*}

由于我们的训练集 $X$ 是一组数据, 我们可以选择两种方式来更新:
 + 每个x更新一次
#+BEGIN_quote
while { \\
  for i = 1 to m { \\
    $w_j = w_j - \alpha (h(x_i) - y) x_j$ (for every j) \\
  } \\
}
#+END_quote
 + 遍历所有x后统一更新
#+BEGIN_quote
while { \\
  $w_j = w_j - \alpha\sum_{i = 1}^m(h(x_i) - y)x_j$ (for every j) \\
}
#+END_quote
另外可以作为折中, 遍历一部分x后再更新.
*** 特征选择问题(多项式)
    特征选择是训练模型之中最重要的一步. 同样的数据在不同的特征下会表现出不同的形态, 甚至变得可以直接使用线性分类器区分. 
比如两个同心圆的点组成的数据,如果使用x,y的坐标系是无法直接使用线性分类器进行区分的. 更多的教材会说明, 如果这时使用极坐标系来表述, 那么就可以在二维平面上变得线性可分. 但是, 如果有人类的进一步的推断, 可以使用每个点距离同心圆圆心的距离作为特征, 那么这个特征可以更加简单的在一维空间上线性区分出两个同心圆的点.

    我们可以看到, 虽然使用相同的数据, 但是通过选择不同的特征, 可以简化特定问题, 以至于可以直接使用简单的线性分类器来进行区分.这也是DNN效果如此之好的一个重要依据. DNN依靠的就是通过深度的增加,将数据非线性的映射到一个不同的空间下, 这一空间可以更加容易的解决训练针对的问题. 而训练的过程就是学习这样的一个非线性映射的过程.

    如果我们处理一个包涵一个维度的数据[x_0], 可能简单的一次的表达式 $y=ax+b$ 并不能符合数据的实际分布, 那么我们可以加入更加复杂的特征, 比如学习 $y=ax^2+bx+c$, 甚至可以学习更加复杂的: $y=ax^3+bx^2+cx+d$ , 这样实际是人工选择了不同的特征, 使得训练的模型更加如何实际数据.
*** Overfitting/正则
    [[./imgs/overfitting.png]]
    
*** 训练方法问题
**** 随即梯度与批量梯度
**** 牛顿法?
**** 验证集/训练集的解释问题
**** Learning Rate相关
*** 感知机的局限(异或问题)

** 多层感知机/ANN
*** 网络结构(linear model + activity function)
*** 激活函数(Sigmoid/ Tanh / ReLU etc.)
*** 前向算法
*** 后向算法
** 无监督学习
*** Autoencoder
** 卷积网络
*** 理解Sobel边界检测
** RNN
   1. http://karpathy.github.io/2015/05/21/rnn-effectiveness/



** 如何构造与应用
* Refs
  1. [[http://machinelearningmastery.com/how-to-layout-and-manage-your-machine-learning-project/][How to Layout and Manage Your Machine Learning Project]]
  2. [[http://www.denizyuret.com/2014/02/machine-learning-in-5-pictures.html][Machine learning in 10 pictures]]
  3. [[https://zh.wikipedia.org/zh/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0][深度学习-wiki]]
  4. [[https://github.com/jatinshah/ufldl_tutorial][Ufldl tutorial in Python]]
  5. https://colah.github.io/posts/2014-07-Conv-Nets-Modular/ [[https://github.com/colah/Conv-Nets-Series][Github]]
  6. http://cs229.stanford.edu/materials.html
  7. http://blog.csdn.net/zouxy09/article/details/8781543
  8. http://www.cnblogs.com/maybe2030/p/4751804.html 牛顿法与随机下降法


